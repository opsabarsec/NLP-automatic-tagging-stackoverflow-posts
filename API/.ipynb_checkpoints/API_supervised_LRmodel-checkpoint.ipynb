{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model to return stackoverflow tags from a clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords \n",
    "from collections import defaultdict \n",
    "from nltk.corpus import wordnet as wn\n",
    "from itertools import chain\n",
    "import re\n",
    "from textblob import TextBlob, Word\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "import spacy \n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yake\n",
    "\n",
    "import pickle as p\n",
    "import json\n",
    "from flask import Flask, jsonify\n",
    "import joblib\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = pd.read_csv('/media/marco/DATA/OC_Machine_learning/section_5/tags_stackoverflow/data-output/stackoverflow_processed_sample.csv', encoding='utf-8')\n",
    "df_base.head()\n",
    "\n",
    "df_tags = pd.read_csv('/media/marco/DATA/OC_Machine_learning/section_5/tags_stackoverflow/data-output/stackoverflow_processed_tags.csv', encoding='utf-8') # load the taglist in order to perform a tags selection\n",
    "df_tags = df_tags.dropna()\n",
    "tags = df_tags.tag #tags ordered by popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_tags = 230 # chosen number of most popular tags\n",
    "popular_tags = tags[:Number_tags].tolist() # get the list of n most popular tags\n",
    "\n",
    "with open('tags.pkl', 'wb') as pickle_out:\n",
    "    p.dump(popular_tags, pickle_out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(popular_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model target from tags\n",
    "one_hot = MultiLabelBinarizer() # encoder for the  tags \n",
    "y = df_base['taglist']\n",
    "y_onehot = one_hot.fit_transform(y.str.split(' ')) \n",
    "y_bin = pd.DataFrame(y_onehot, columns=one_hot.classes_ ) # transform it to Pandas object\n",
    "y_bin = y_bin.filter(items=popular_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfVectorizer = TfidfVectorizer(norm=None,analyzer='word',min_df = 5, max_df = 0.8, ngram_range=(1,2),max_features = 400, use_idf=True)\n",
    "# TF-IDF matrices\n",
    "tfidfvect = tfidfVectorizer.fit(df_base['Lemma'])\n",
    "TF_IDF = tfidfvect.transform(df_base['Lemma'])\n",
    "\n",
    "TF_IDF_dense = TF_IDF.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(tfidfvect, 'vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80/20 split TF-IDF\n",
    "X_train, X_test,X_tfidf_train, X_tfidf_test, y_train, y_test, y_train_bin, y_test_bin = train_test_split(df_base['Lemma'],TF_IDF_dense, y, y_bin,  test_size=0.2,train_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf = RandomForestClassifier(max_depth=30000, random_state=42, n_jobs = -1, n_estimators=100)#, parameters optimized to balance consumption and accuracy\n",
    "lr = LogisticRegression()\n",
    "clf = MultiOutputClassifier(lr)\n",
    "lr_clf = clf.fit(X_tfidf_train, y_train_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lr_clf , 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower() # lowercase\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub(r\"[0-9]\", \" \", text)\n",
    "    text = re.sub(r\"[?.!/;:']\", \" \", text)\n",
    "    text = re.sub(r\"[<>\\@%*=]\", \" \", text)\n",
    "    text = re.sub(r\"[\\ |\\]|\\[|\\|\\/|\\#|\\:]\", \" \", text)\n",
    "    text = re.sub(r\"\\'\\n\", \" \", text) #line breaks\n",
    "    text = re.sub(r\"\\'\\xa0\", \" \", text) # xa0 Unicode representing spaces\n",
    "    text = re.sub('\\s+', ' ', text) # one or more whitespace characters\n",
    "    text = text.strip(' ') # spaces\n",
    "    list_tokens = word_tokenize(text)\n",
    "    return list_tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['when', 'i', 'have', 'firefox', 'running', 'on', 'an', 'android', 'phone', 'can']\n"
     ]
    }
   ],
   "source": [
    "query = 'When I have firefox running on an android phone can I use a a python or java function on firefox?'\n",
    "tokens = preprocess_text(query)\n",
    "tfidfVectorizer = load(\"vectorizer.pkl\")\n",
    "\n",
    "def vectorize_query(tokens):\n",
    "    vectorized_query = tfidfVectorizer.transform(tokens).todense()\n",
    "    return vectorized_query\n",
    "vectorize_query(tokens)\n",
    "print(tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def vectorize_query(tokens):\n",
    "#    vectorized_query = tfidfVectorizer.transform(tokens).todense()\n",
    "#    return vectorized_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tags(vectorized_query):\n",
    "    model = load('model.pkl')\n",
    "    y_preds= model.predict(vectorized_query)\n",
    "    popular_tags = load('tags.pkl')\n",
    "    df_probs = pd.DataFrame(y_preds, columns= popular_tags).T\n",
    "    df_probs[\"probability\"] = df_probs.sum(axis=1)\n",
    "    df_probs.reset_index(inplace=True)\n",
    "    \n",
    "    df_probs = df_probs.sort_values(by='probability', ascending=False)\n",
    "    tags = df_probs['index'][:5].tolist()\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_query =  tfidfVectorizer.transform(tokens).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds= lr_clf.predict(vectorized_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230, 22)\n",
      "['python', 'java', 'android', 'ssl', 'unicode']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>python</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>java</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>android</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>ssl</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>unicode</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  0  1  2  3  4  5  6  7  8  ...  11  12  13  14  15  16  17  18  \\\n",
       "1     python  0  0  0  0  0  0  0  0  0  ...   0   0   0   1   0   0   0   0   \n",
       "2       java  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   1   0   0   \n",
       "4    android  0  0  0  0  0  0  0  1  0  ...   0   0   0   0   0   0   0   0   \n",
       "159      ssl  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   \n",
       "147  unicode  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   \n",
       "\n",
       "     19  probability  \n",
       "1     0            1  \n",
       "2     0            1  \n",
       "4     0            1  \n",
       "159   0            0  \n",
       "147   0            0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#popular_tags = ['javascript', 'python', 'java', 'c#', 'android', 'html', 'git', 'css', 'jquery', 'c++', 'ios', '.net', 'php', 'string', 'sql', 'mysql', 'node.js', 'bash', 'arrays', 'c', 'linux', 'objective-c', 'sql-server', 'ruby', 'swift', 'json', 'shell', 'ruby-on-rails', 'iphone', 'angularjs', 'list', 'windows', 'xcode', 'regex', 'r', 'visual-studio', 'performance', 'asp.net', 'database', 'macos', 'asp.net-mvc', 'eclipse', 'django', 'github', 'datetime', 'angular', 'unix', 'postgresql', 'vim', 'reactjs']\n",
    "df_probs = pd.DataFrame(y_preds, columns= popular_tags).T\n",
    "#df_probs.loc[:, 'probability'] = df_probs[0].map(lambda x: x[1]) # get out only positive probability\n",
    "df_probs[\"probability\"] = df_probs.sum(axis=1)\n",
    "df_probs.reset_index(inplace=True)\n",
    "print(df_probs.shape)\n",
    "df_probs = df_probs.sort_values(by='probability', ascending=False)\n",
    "tags = df_probs['index'][:5].tolist()\n",
    "print(tags)\n",
    "df_probs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
